{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1_CSE_6240_template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fi_VO8r3R1TT"
      },
      "source": [
        "# Analyzing A Movie Review Dataset[100 Points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gd1nFWBCP7GC"
      },
      "source": [
        "## 0. Text Preprocessing [10 Points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gaeN3k-w_ygu"
      },
      "source": [
        "Read through this tutorial on kaggle [here](\n",
        "https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words) , to\n",
        "familiarize yourself with its python tools and workflow. You'll have to download \"labeledTrainData.tsv\" and \"testData.tsv\" from [here](https://www.kaggle.com/c/word2vec-nlp-tutorial/data). Please remember to add your GT_UserName in the author function below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IZAcFI1WbCc4",
        "outputId": "9a5a4fef-1eaf-4e4b-f5c7-7fcae9e608c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def author(gt_username = 'pburdell3'):\n",
        "    print(\"This assignment is submitted by {0}.\".format(gt_username))\n",
        "\n",
        "#Add your GT_UserName below and uncomment the line.\n",
        "author('sroy86')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This assignment is submitted by sroy86.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UIpeJ8VmR1TX",
        "colab": {}
      },
      "source": [
        "#Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import re\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from copy import deepcopy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics.pairwise import pairwise_distances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CIvs0LVJR1Te",
        "colab": {}
      },
      "source": [
        "# Reading in the data\n",
        "train = pd.read_csv(\"labeledTrainData.tsv\", delimiter=\"\\t\")\n",
        "test = pd.read_csv(\"testData.tsv\", delimiter=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ano1yq7oR1Th",
        "colab": {}
      },
      "source": [
        "def preprocess_review(review):\n",
        "    \"\"\"Helper function to clean the reviews.\n",
        "\n",
        "     Arg: review: review text.\n",
        "     Returns: clean_review : Cleaned reviews\n",
        "\n",
        "     You should carry out the following steps.\n",
        "     1. Remove HTML Tags.\n",
        "     2. Remove non-letter characters.\n",
        "     3. Convert to lower case.\n",
        "     4. Remove stopwords.\n",
        "    \"\"\"\n",
        "\n",
        "    #Write your code below.\n",
        "    \n",
        "    ## HTML Tags removal\n",
        "    clean1=BeautifulSoup(review)  \n",
        "    \n",
        "    ## Non-letter characters removal\n",
        "    clean2=re.sub(\"[^a-zA-Z]\", \" \", clean1.get_text()) \n",
        "    \n",
        "    ## Converting to lower case and splitting each word\n",
        "    clean3=clean2.lower().split()\n",
        "    \n",
        "    ## Removing stopwords\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    clean4=[w for w in clean3 if not w in stops]\n",
        "    \n",
        "    ## Returning the reviews with spaces between words\n",
        "    clean_review=\" \".join(clean4)\n",
        "\n",
        "    \n",
        "    return clean_review\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FJERbiU0R1Tj",
        "outputId": "874ab537-823f-4622-d9fd-d32ca8d86043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Clean the reviews and add them to the list below\n",
        "cleaned_reviews = []\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#Write your code below.\n",
        "num_reviews = train[\"review\"].size\n",
        "for i in range(0, num_reviews):\n",
        "    cr=preprocess_review(train[\"review\"][i])\n",
        "    cleaned_reviews.append(cr)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dIq31H_fR1Tm"
      },
      "source": [
        "## 1. Processing Text to create Design Matrices [15 Points]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urCR0VMaR1Tn",
        "colab": {}
      },
      "source": [
        "def design_matrix(cleaned_reviews):\n",
        "    \"\"\" Generate the 4 design matrices X_counts, X_binary, X_tfidf, X_binary_imbalance.\n",
        "\n",
        "      Args: cleaned_reviews: Cleaned Reviews.\n",
        "      Returns:\n",
        "            X_counts: Design Matrix X_counts.\n",
        "            X_binary: Design Matrix X_binary(Use the X_counts to generate this.)\n",
        "            X_tfidf:  Design Matrix X_tfidf\n",
        "            X_binary_imbalance: Design Matrix X_binary_imbalance(use fraction 0.75)\n",
        "            imbalance_train: Skewed training set(use fraction 0.75)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #Write your code here.\n",
        "  \n",
        "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
        "                                tokenizer = None,    \\\n",
        "                                preprocessor = None, \\\n",
        "                                stop_words = None,   \\\n",
        "                                max_features = 5000) \n",
        "\n",
        "    train_data_features = vectorizer.fit_transform(cleaned_reviews)\n",
        "\n",
        "    X_counts = train_data_features.toarray()\n",
        "\n",
        "    X_binary=X_counts\n",
        "\n",
        "    X_binary[X_binary>0]=1\n",
        "\n",
        "    transformer = TfidfTransformer()\n",
        "\n",
        "    X_tfidf = transformer.fit_transform(X_counts).toarray()\n",
        "\n",
        "    a=X_binary.tolist()\n",
        "\n",
        "    train['binary']=['-'.join([str(x) for x in my_list]) for my_list in a]\n",
        "\n",
        "    train_imbalance_df = train.drop(train.query('sentiment == 1').sample(frac=0.75, random_state=0).index)\n",
        "\n",
        "    X_binary_imbalance_list = list(train_imbalance_df['binary'])\n",
        "\n",
        "    X_binary_imbalance = np.array([[int(j) for j in i.split('-')] for i in X_binary_imbalance_list])\n",
        "\n",
        "    imbalance_train = train_imbalance_df[['id', 'sentiment', 'review']]\n",
        "    \n",
        "\n",
        "    return X_counts,X_binary,X_tfidf,X_binary_imbalance,imbalance_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "POPvMtKER1Tp",
        "outputId": "acfd4abf-31da-489c-b0df-c2e7f8764b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "X_counts,X_binary,X_tfidf,X_binary_imbalance,imbalance_train = design_matrix(cleaned_reviews) \n",
        "X_counts"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5kt4EPPLR1Tx",
        "outputId": "70f2f1ca-c502-48a7-c480-bf04303987dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "X_binary"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xBH1DKHuR1T1",
        "outputId": "0079b6e1-25d9-47de-cf09-b85664b25794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "X_tfidf"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hcHBxl31R1T7",
        "outputId": "9ab6b317-dd5f-4091-d4ea-1e848057b4e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "X_binary_imbalance"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F5s2xUvMR1T-"
      },
      "source": [
        "## 2. Feature Space Similarity Experiment [25(5 + 5 + 15) Points]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LRPAXIfDR1T_",
        "colab": {}
      },
      "source": [
        "# Obtain the label on the original train set and imbalance train set\n",
        "train_sentiment = train[\"sentiment\"].values\n",
        "imbalance_train_sentiment = imbalance_train[\"sentiment\"].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rgK6cWOKUhIJ",
        "colab": {}
      },
      "source": [
        "def dist(X, i, j, distance_function = \"euclidean\"):\n",
        "    \"\"\"The distance function returns the (Euclidean) distance between rows i and j of a design matrix.\n",
        "     Args: X : Design Matrix\n",
        "           i,j: row IDs\n",
        "           distance_function: The distance function to be used. Here we are using euclidean\n",
        "     Returns: The distance between row i and row j.\n",
        "  \n",
        "    \"\"\"\n",
        "    #Write your code here.\n",
        "    distance=np.linalg.norm(X[i,:]-X[j,:])\n",
        "\n",
        "    return distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cWvROZUqUnvJ",
        "colab": {}
      },
      "source": [
        "def topk(X, k):\n",
        "    \"\"\"The topk(X, k) function returns ((i1,j1,d1),...(ik,jk,dk)) where (ix,jx) are the indices of the xth \n",
        "     closest pair, and dx is the corresponding distance. You can break ties randomly.\n",
        "     Args: X : Design Matrix\n",
        "           k:  Top k\n",
        "     Returns: top: A list of [row,col,distance]\n",
        "  \n",
        "    \"\"\"\n",
        "   \n",
        "    #Write your code here.\n",
        "    maxdist=0\n",
        "    toplist=[]\n",
        "    Xsize=X.shape[0]\n",
        "    flag=0\n",
        "    for i in range(Xsize):\n",
        "        for j in range(i+1, Xsize):\n",
        "            Dist=dist(X, i, j)\n",
        "            if len(toplist)<k:\n",
        "                toplist.append([i, j, Dist])\n",
        "                toplist.sort(key = lambda x: x[2])\n",
        "                maxdist=toplist[-1][2]\n",
        "            elif Dist<maxdist or (Dist==maxdist and np.random.uniform()>0.5):\n",
        "                toplist.pop()\n",
        "                toplist.append([i, j, Dist])\n",
        "                toplist.sort(key = lambda x: x[2])\n",
        "                maxdist=toplist[-1][2] \n",
        "            if maxdist==0 and len(toplist)==k:\n",
        "                flag=-1\n",
        "                break\n",
        "        if flag==-1:\n",
        "            break\n",
        "\n",
        "    top = tuple([tuple(i) for i in toplist])\n",
        "      \n",
        "    return top"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z6QQdWA7BmMZ"
      },
      "source": [
        "Use topk() to find the closest review pairs for each design matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L-pJSPn0a3NA",
        "outputId": "24304084-34ad-447a-dd7e-c224e5445710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# compute top k for X_counts matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
        "#Write your code here.\n",
        "i, j, Dist=topk(X_counts, 1)[0]\n",
        "print('Minimum inter-row distance:', Dist)\n",
        "print('index_1:', i, '; review20_1:', train['review'][i][:20], '; label_1:', train['sentiment'][i])\n",
        "print('index_2:', j, '; review20_2:', train['review'][j][:20], '; label_2:', train['sentiment'][j])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum inter-row distance: 0.0\n",
            "index_1: 37 ; review20_1: Dumb is as dumb does ; label_1: 0\n",
            "index_2: 5536 ; review20_2: Dumb is as dumb does ; label_2: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TkvjeJMTaFTS",
        "outputId": "ca7a3840-18b4-4620-9462-1e306fad2eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# compute top k for X_binary matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
        "#Write your code here.\n",
        "i, j, Dist=topk(X_binary, 1)[0]\n",
        "print('Minimum inter-row distance:', Dist)\n",
        "print('index_1:', i, '; review20_1:', train['review'][i][:20], '; label_1:', train['sentiment'][i])\n",
        "print('index_2:', j, '; review20_2:', train['review'][j][:20], '; label_2:', train['sentiment'][j])\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum inter-row distance: 0.0\n",
            "index_1: 37 ; review20_1: Dumb is as dumb does ; label_1: 0\n",
            "index_2: 5536 ; review20_2: Dumb is as dumb does ; label_2: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OITNkuZUaOu_",
        "outputId": "9b10d948-33c8-4c2e-e0d3-ad2d6b448803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# compute top k for X_tfidf matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
        "#Write your code here.\n",
        "i, j, Dist=topk(X_tfidf, 1)[0]\n",
        "print('Minimum inter-row distance:', Dist)\n",
        "print('index_1:', i, '; review20_1:', train['review'][i][:20], '; label_1:', train['sentiment'][i])\n",
        "print('index_2:', j, '; review20_2:', train['review'][j][:20], '; label_2:', train['sentiment'][j])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum inter-row distance: 0.0\n",
            "index_1: 37 ; review20_1: Dumb is as dumb does ; label_1: 0\n",
            "index_2: 5536 ; review20_2: Dumb is as dumb does ; label_2: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ckNqY0ZbaU-z",
        "outputId": "161aec1a-af37-4a14-9d7b-23479ad268c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# compute top k for X_binary_imbalance matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
        "#Write your code here.\n",
        "retained_rows=list(imbalance_train.index)\n",
        "i, j, Dist=topk(X_binary_imbalance, 1)[0]\n",
        "i, j=retained_rows[i], retained_rows[j]\n",
        "print('Minimum inter-row distance:', Dist)\n",
        "print('index_1:', i, '; review20_1:', train['review'][i][:20], '; label_1:', train['sentiment'][i])\n",
        "print('index_2:', j, '; review20_2:', train['review'][j][:20], '; label_2:', train['sentiment'][j])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum inter-row distance: 0.0\n",
            "index_1: 37 ; review20_1: Dumb is as dumb does ; label_1: 0\n",
            "index_2: 5536 ; review20_2: Dumb is as dumb does ; label_2: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ESA7ElrMbHEw"
      },
      "source": [
        "Are the pairs always the same?\n",
        "\n",
        "No, there are data points with similar reviews, so there are multiple instances of zero-distance. Due to computational limitations, we break away from the distance comparision code whenever we see the maximum distance in the list is zero since we know we could not get a sub-zero distance between two points. \n",
        "\n",
        "Just like 37-5536 pair has shown to have same review, we actually encounter similar other identical pairs like 326-7336, 428-14579, 531-9467, etc.\n",
        "\n",
        "So, whether we come up with the same pair or not will depend on how we break tie for those zero-distance instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yywNrWhlbQ10"
      },
      "source": [
        "## 3. Classification Experiment [35 Points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mo8UaxPjCr9Q"
      },
      "source": [
        "Now you’re going to tune an SVM classifier using each design matrix, and measure the\n",
        "resultant performance. Read the sklearn [docs](http://scikit-learn.org/stable/modules/cross_validation.html) on cross-validation to see the\n",
        "methods to use.\n",
        "*   Set your rng seed to 0 and create an initial learning_set / test_set split of 80-20.\n",
        "*   Now we want to use a linear SVM (svm.SVC with kernel=linear) and pick the best C value for our classifier.\n",
        "*   Repeat for each of the four design matrices:\n",
        "  *  Repeat 30 times:\n",
        "    *  Pick a random value of C uniformly in the interval (1e-4, 1e4).\n",
        "    *  Use 5-fold cross-validation to train the SVM.\n",
        "    *  Estimate and record the F1-Score.\n",
        "  *  Select the value of C which produced the best F1-Score and find out the F1-Score on the test set using that C.\n",
        "  *  Retrain the classifier using the entire learning set with this C value.\n",
        "  *  Submit test set predictions to Kaggle (see the section in the blog, and\n",
        "make sure you use their test data. You may need to retrain one more\n",
        "time using all “training data”). Print your Kaggle score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t9La4ICibWl6",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random as rd\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CD98GcZ9jJ2b"
      },
      "source": [
        "### 3.1 Utility Functions [10 (5 + 5) Points]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N9K2mD7pe9Bc",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "def calculateF1(X, y, k = 5):\n",
        "    \"\"\"calculateF1(X, y, k = 5) return two list which record all randomly selected c(in the interval (1e-4, 1e4))\n",
        "     and corresponding F1 scores.\n",
        "\n",
        "     Args: X: Features\n",
        "           y: Label of sentiment\n",
        "           k: Number of Cross-validation\n",
        "\n",
        "     Returns: c_list: List of all c values.\n",
        "              f1_list: Corresponding F1 Scores.\n",
        "    \"\"\"\n",
        "    rd.seed(0) #Setting a common seed\n",
        "\n",
        "    #Write your code here.\n",
        "    start=time.time()\n",
        "    c_list=[10**i for i in np.random.uniform(-4, 4, 30)]\n",
        "    f1_list=[]\n",
        "    kf = KFold(n_splits=k)\n",
        "    print('itr# Time')\n",
        "    i=0\n",
        "    for c in c_list:\n",
        "        f1score=0.0\n",
        "        i+=1\n",
        "        for train_index, test_index in kf.split(X):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "            clf = svm.LinearSVC(C=c, max_iter=10000)\n",
        "            clf = clf.fit(X_train, y_train)\n",
        "            y_pred_test = clf.predict(X_test)\n",
        "            f1score+=f1_score(y_test, y_pred_test)/float(k)\n",
        "        f1_list.append(f1score)\n",
        "        if i%5==0:\n",
        "            print(i, time.time()-start)        \n",
        "        \n",
        "    return c_list, f1_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ah82TDqCgKaN",
        "colab": {}
      },
      "source": [
        "def findBestC(X, y, k = 5):\n",
        "    \"\"\"findBestC(X, y, k) return the best performance c, and the improvement(difference between best and worst f1_scores)/\n",
        "     Args: X: Features\n",
        "           y: Label of sentiment\n",
        "           k: Number of Cross-validation\n",
        "     Returns: c_best: C value with best f1_score.\n",
        "              improvement: difference between best and worst f1_score.\n",
        "    \"\"\"\n",
        "    #Write your code here. \n",
        "    c_list, f1_list = calculateF1(X, y, k)\n",
        "    f1max = max(f1_list)\n",
        "    c_best = c_list[f1_list.index(f1max)]\n",
        "    improvement = f1max - min(f1_list)\n",
        "    return c_best,improvement"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aAMZU6YBjUVU"
      },
      "source": [
        "### 3.2 Tune an SVM classifier using X_counts [20 (4*5) Points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IVatM_PprZpC"
      },
      "source": [
        "#### 3.2.0 Utility Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AFjJKZKelYl5",
        "colab": {}
      },
      "source": [
        "def findImprovement(X,train_sentiment,test_size = 0.2, random_state = 0):\n",
        "    \"\"\" Find the improvement in F1-Score of the design Matrix(X) using previous utility functions and the test_f1_score using the best C.\n",
        "\n",
        "      Args: X: Design Matrix\n",
        "            train_sentiment: Sentiments of the training data\n",
        "            test_size: Split it as 80:20\n",
        "            random_state: Seed\n",
        "\n",
        "      Returns:\n",
        "            c_best: The best possible c value\n",
        "            improvement: improvement in F1-Score using the design Matrix(X).\n",
        "            f1_s: Test F1 Score.\n",
        "            \n",
        "\n",
        "      You should carry out the following Steps:\n",
        "      1. Split the data using the above parameters.\n",
        "      2. Find out the best c and the improvement. (use 5-fold Cross Validation.)\n",
        "      3. Find out the test f1 score with this c.\n",
        "    \"\"\"\n",
        "    #Write your code here.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, train_sentiment, test_size=test_size, random_state=random_state)\n",
        "    c_best, improvement = findBestC(X_train, y_train)\n",
        "    clf = svm.LinearSVC(C=c_best, max_iter=10000)\n",
        "    clf = clf.fit(X_train, y_train)\n",
        "    y_pred_test = clf.predict(X_test)\n",
        "    f1_s = f1_score(y_test, y_pred_test)   \n",
        "\n",
        "    return c_best,improvement,f1_s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f90fpHRiq1IM"
      },
      "source": [
        "#### 3.2.1 Tune an SVM classifier using X_counts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vtON_6r5jgTL",
        "outputId": "93906a3e-acd4-419c-89d4-fc737483a308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Print the improvement using X_counts and the test f1_score using the best c.\n",
        "#Write your code here.\n",
        "c_best,improvement,f1_s = findImprovement(X_counts,train_sentiment)\n",
        "print('best c:', c_best, '; improvement:', improvement, '; test f1_score:', f1_s)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "itr# Time\n",
            "5 98.57039380073547\n",
            "10 292.7220823764801\n",
            "15 401.93008494377136\n",
            "20 519.6036071777344\n",
            "25 717.0939176082611\n",
            "30 931.5495858192444\n",
            "best c: 0.007510861577617194 ; improvement: 0.05637641720905007 ; test f1_score: 0.8729392842782469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IygnGs8blBu-",
        "colab": {}
      },
      "source": [
        "# Retrain the classifier using the entire learning set with c_best\n",
        "#Write your code here.\n",
        "clf = svm.LinearSVC(C=c_best, max_iter=10000)\n",
        "clf = clf.fit(X_counts, train_sentiment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IunoAYI6pgZW"
      },
      "source": [
        "Submit test set predictions to Kaggle (see the section in the blog, and\n",
        "make sure you use their test data. You may need to retrain one more\n",
        "time using all “training data”). Print your Kaggle scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9aRF1HA7lHAP",
        "outputId": "0a99e991-c9d6-4eab-b0e1-30859c5e64d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#You should do the following steps.\n",
        "#1. Create bag of words from the test data.\n",
        "#2. Generate the labels using that test data.\n",
        "#3. Save the results to the pandas dataframe. For format check the blog.\n",
        "#4. Submit the results to Kaggle and add the scores here.\n",
        "\n",
        "# #Write your code here.\n",
        "cleaned_reviews_test = []\n",
        "\n",
        "#Write your code below.\n",
        "num_reviews = test[\"review\"].size\n",
        "for i in range(0, num_reviews):\n",
        "    cr=preprocess_review(test[\"review\"][i])\n",
        "    cleaned_reviews_test.append(cr)\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
        "                            tokenizer = None,    \\\n",
        "                            preprocessor = None, \\\n",
        "                            stop_words = None,   \\\n",
        "                            max_features = 5000) \n",
        "\n",
        "test_data_features = vectorizer.fit_transform(cleaned_reviews_test)\n",
        "\n",
        "X_counts_test = test_data_features.toarray()\n",
        "\n",
        "X_binary_test=X_counts_test\n",
        "\n",
        "X_binary_test[X_binary_test>0]=1\n",
        "\n",
        "transformer = TfidfTransformer()\n",
        "\n",
        "X_tfidf_test = transformer.fit_transform(X_counts_test).toarray()  \n",
        "\n",
        "test['sentiment'] = clf.predict(X_counts_test)\n",
        "\n",
        "test[['id', 'sentiment']].to_csv('counts_test.csv', encoding='utf-8', index=False)\n",
        "\n",
        "#Uncomment the below lines and add your score.\n",
        "X_counts_result = 0.55516\n",
        "print(\"The Kaggle Score using X_counts is {}\".format(X_counts_result))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Kaggle Score using X_counts is 0.55516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cYRrpQtvrAKF"
      },
      "source": [
        "#### 3.2.2 Tune an SVM classifier using X_binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jVwbgdUJrD5h",
        "outputId": "775c6ae3-a4b6-45c6-cd64-95f81465db42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Print the improvement using X_binary and the test f1_score using the best c.\n",
        "#Write your code here.\n",
        "c_best,improvement,f1_s = findImprovement(X_binary,train_sentiment)\n",
        "print('best c:', c_best, '; improvement:', improvement, '; test f1_score:', f1_s)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "itr# Time\n",
            "5 139.28588390350342\n",
            "10 269.8989577293396\n",
            "15 342.65047121047974\n",
            "20 531.0666551589966\n",
            "25 703.6163303852081\n",
            "30 797.1101348400116\n",
            "best c: 0.0024125942153262587 ; improvement: 0.0582855521323693 ; test f1_score: 0.8740710986141796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hI0KVsQjsGHa",
        "colab": {}
      },
      "source": [
        "# Retrain the classifier using the entire learning set with c_best\n",
        "#Write your code here.\n",
        "clf = svm.LinearSVC(C=c_best, max_iter=10000)\n",
        "clf = clf.fit(X_binary, train_sentiment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-zpgOR4NsdrP",
        "outputId": "8b680597-031d-4f30-9fcd-643fa437522c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Use the the same steps as you did for X_counts and print the kaggle score. Please note that you need to find X_binary_test using the X_counts_test.\n",
        "#Write your code here.\n",
        "test['sentiment'] = clf.predict(X_binary_test)\n",
        "test[['id', 'sentiment']].to_csv('binary_test.csv', encoding='utf-8', index=False)\n",
        "\n",
        "#Uncomment the below lines and add your score.\n",
        "X_binary_result = 0.57084\n",
        "print(\"The Kaggle Score using X_binary is {}\".format(X_binary_result))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Kaggle Score using X_binary is 0.57084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sRHMJO2os_tc"
      },
      "source": [
        "#### 3.2.3 Tune an SVM classifier using X_tf_idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xnm8PdFWtGE9",
        "outputId": "69076349-11bb-4283-9ac3-5a822b87455a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Print the improvement using X_tf_idf and the test f1_score using the best c.\n",
        "#Write your code here.\n",
        "c_best,improvement,f1_s = findImprovement(X_tfidf, train_sentiment)\n",
        "print('best c:', c_best, '; improvement:', improvement, '; test f1_score:', f1_s)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "itr# Time\n",
            "5 205.2684142589569\n",
            "10 346.64279985427856\n",
            "15 474.50623846054077\n",
            "20 499.06809258461\n",
            "25 527.1646299362183\n",
            "30 725.3782649040222\n",
            "best c: 0.21744406337194058 ; improvement: 0.06215956228267838 ; test f1_score: 0.8818200120797262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KWXXKrgGtU-r",
        "colab": {}
      },
      "source": [
        "# Retrain svm using all X_tfidf data\n",
        "#Write your code here.\n",
        "clf = svm.LinearSVC(C=c_best, max_iter=10000)\n",
        "clf = clf.fit(X_tfidf, train_sentiment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "waBnpKAztX_H",
        "outputId": "199b3d5d-25e5-4f37-aa67-22f50024803f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Use the the same steps as you did for X_counts and print the kaggle score. Please note that you need to find X_tfidf_test using the X_counts_test.\n",
        "\n",
        "#Write your code here.\n",
        "test['sentiment'] = clf.predict(X_tfidf_test)\n",
        "test[['id', 'sentiment']].to_csv('tfidf_test.csv', encoding='utf-8', index=False)\n",
        "\n",
        "#Uncomment the below lines and add your score.\n",
        "X_tfidf_result = 0.5784\n",
        "print(\"The Kaggle Score using X_tfidf is {}\".format(X_tfidf_result))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Kaggle Score using X_tfidf is 0.5784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GSTHOCktwVf"
      },
      "source": [
        "#### 3.2.4 Tune an SVM classifier using X_binary_imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OWPad9EXtzKD",
        "outputId": "a2c7525f-309a-404f-b813-85a810265bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Print the improvement using X_binary_imbalance and the test f1_score using the best c.\n",
        "#Write your code here.\n",
        "c_best,improvement,f1_s = findImprovement(X_binary_imbalance, imbalance_train_sentiment)\n",
        "print('best c:', c_best, '; improvement:', improvement, '; test f1_score:', f1_s)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "itr# Time\n",
            "5 28.88272190093994\n",
            "10 104.72456789016724\n",
            "15 198.97556114196777\n",
            "20 248.45314025878906\n",
            "25 283.06400299072266\n",
            "30 358.1304633617401\n",
            "best c: 0.008920535767622903 ; improvement: 0.214797834552796 ; test f1_score: 0.7139107611548557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oUsNuBpouEL-",
        "colab": {}
      },
      "source": [
        "# Retrain svm using all X_binary_imbalance data.\n",
        "#Write your code here.\n",
        "clf = svm.LinearSVC(C=c_best, max_iter=10000)\n",
        "clf = clf.fit(X_binary_imbalance, imbalance_train_sentiment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a6YJvYHkuFh8",
        "outputId": "f777d12a-5e52-446c-cac6-e4ced8917af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Use the the same steps as you did for X_counts and print the kaggle score.\n",
        "\n",
        "#Write your code here.\n",
        "test['sentiment'] = clf.predict(X_counts_test)\n",
        "test[['id', 'sentiment']].to_csv('imbalance_test.csv', encoding='utf-8', index=False)\n",
        "\n",
        "#Uncomment the below lines and add your score.\n",
        "X_binary_imbalance_result = 0.5172\n",
        "print(\"The Kaggle Score using X_binary_imbalance is {}\".format(X_binary_imbalance_result))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Kaggle Score using X_binary_imbalance is 0.5172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mRxZro0LMixK"
      },
      "source": [
        "Which design matrix performed best (e.g., which encoding method worked best)?\n",
        "What was the lift (improvement in F1-Score) between the worst and best cases for each experiment?\n",
        "\n",
        "Based on Kaggle score, X_tfidf had the best result (0.5784).\n",
        "\n",
        "With binary imbalance having less data points, the computation time reduced drastically. \n",
        "\n",
        "F1-score improvement:\n",
        "\n",
        "X_counts: 0.05637641720905007\n",
        "\n",
        "X_binary: 0.0582855521323693 \n",
        "\n",
        "X_tfidf: 0.06215956228267838 \n",
        "\n",
        "X_binary_imbalance: 0.214797834552796\n",
        "\n",
        "Note: Instead of choosing uniformly from [1e-4, 1e4] for c values, I have chosen uniformly from [-4, 4] and raised them to the power of 10 (as suggested by a discussion thread on Piazza). That way, more spectrum of orders of magnitude could be covered. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DFjZq14Subsb"
      },
      "source": [
        "##4. Learning Curve Experiment [15(10 + 5) Points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LfArmX7M0-9"
      },
      "source": [
        "Using a logistic regression classifier and the design matrix X_counts, generate a learning curve:\n",
        "*  Set your rng seed to 0 and create an initial learning_set / test_set split of 80-20.\n",
        "*  Generate a learning curve (xval vs training error) for n=(100, 500, 1000, 2000,3000, 4000, 5000, 7500, 10000, 15000, 20000) training instances.\n",
        "*  Interpret the learning curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZy1W2wCNRrU",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import learning_curve"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQYNGVZYugpY",
        "outputId": "7a1b3267-e262-4ded-ce29-783682609eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "training_instances = [100, 500, 1000, 2000, 3000, 4000, 5000, 7500, 10000, 15000, 20000]\n",
        "#Use the learning_curve module to generate mean train and test scores and plot them with X-axis being the number of training instances and Y-axis.\n",
        "#Please add appropriate title,labels and legends.\n",
        "#Write your code here.\n",
        "train_sizes, train_scores, valid_scores = learning_curve(LogisticRegression(), X_counts, train_sentiment, train_sizes=training_instances, cv=5, random_state=0)\n",
        "\n",
        "plt.plot(training_instances, [1-sum(i)/len(i) for i in valid_scores], marker='o', label='Cross-validation Error')\n",
        "plt.plot(training_instances, [1-sum(i)/len(i) for i in train_scores], marker='o', label='Training Error')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of Training Instances')\n",
        "plt.ylabel('Error')\n",
        "plt.title('Learning Curve: Logistic Regression')\n",
        "plt.show()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xm0dRZbpScvV"
      },
      "source": [
        "##### Please provide an explanation to the nature of your graph in the above experiment.\n",
        "\n",
        "The learning curve shows that training error increases with increased training data set. At the same time cv error reduces with increase in training data size and eventually there is a gap between the two. This is an example of a training algorithm that has high variance."
      ]
    }
  ]
}