\documentclass[sigconf,authordraft]{acmart}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

\usepackage{enumitem}
\usepackage{float}
\setcopyright{acmcopyright}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{10.1145/1122445.1122456}



\begin{document}
\sloppy

\title{User-Customized Restaurant Recommendation using Natural Language Processing on Yelp Data}
\subtitle{Course project for CSE 6240: Web Search and Text Mining, Spring 2020}


\author{Somdut Roy}
\authornotemark[1]

\affiliation{%
  \institution{Georgia Institute of Technology}
  \streetaddress{North Ave NW}
  \city{Atlanta}
  \state{Georgia}
  \postcode{30313}
  \country{USA}}
\email{somdut.roy@gatech.edu}
%}

\author{Devanshee Shah}
\affiliation{%
  \institution{Georgia Institute of Technology}
  \streetaddress{North Ave NW}
  \city{Atlanta}
  \state{Georgia}
  \postcode{30313}
  \country{USA}}
\email{dshah330@gatech.edu}



\author{Vitaly V. Marin}
\affiliation{%
  \institution{Georgia Institute of Technology}
  \streetaddress{North Ave NW}
  \city{Atlanta}
  \state{Georgia}
  \postcode{30313}
  \country{USA}}
\email{vmarin3@gatech.edu}



\begin{abstract}
Using machine learning tools for natural language processing (NLP) has been prevalent in different avenues across the globe. With numerous sources of available data in textual format, it would be interesting to leverage such information to gain useful insights. Yelp data is one such readily available and insightful data avenue. This study uses a set of a reviews and the corresponding ratings for a restaurant for one city and creates a rating prediction tool using i) Linear SVM and ii) Logistic Regression. At the same time, the provided ratings are used to recommend relevant restaurants to a user mentioned his/her favourite restaurant. Considering Computation Time and Accuracy for both the models, logistic regression was chosen over SVM. Later, rating prediction and Item based collaborative filtering were merged to devise a tool that recommends a user, who has a favorite restaurant, a list of restaurants along with the hybrid ratings along with the distance and predicted rating. Although our built model is little less accurate than baselines, it allows to have predicted rating for the users  for a restaurants without having visited or rated them unlike baselines. Lastly, an app was created using python library to make it more interactive. 

\end{abstract}


\keywords{NLP, recommender systems, Yelp, item-based collaborative filtering, rating, reviews, kNN, Logistic Regression}


\maketitle


\section{Introduction}
Use of Natural Language Processing (NLP) has shown unlimited potential since the start of this millennium. With different avenues of public textual data at our disposal, we are presented with exploring different NLP tools/ techniques learnt in this course to solve real-life problems. Kaggle has proven to be a reliable and significantly large repository of such data sets and in this current study we have used a portion of one such data-set to perform our analyses. 

Yelp has systematically harboured enormous amount of data from different users in relation to their experiences with restaurants, small businesses and startups in the form of textual reviews and ratings ranging from 1 to 5. They provide valuable insight to a new user searching for recommendations or a business owner using the feedback as a way to better different aspects of their services. In the current study, we try to build a recommender system using item-based collaborative filtering and add another layer of predicted feedback to it that makes the decision making for users easier and more convenient. The addition of another layer of feedback heavily rely on sentiment analysis performed based on the reviews using SVM and Logistic Regression models. To limit the scope of our study, we have chosen restaurants in Avondale, AZ. Eventually, we aim to  build a search engine that will take the favourite restaurant name from a given user and suggest a number of restaurants in the order that takes both relevance and fondness of the user into account. While comparing our technique with the baselines, it performs slightly worse than the baselines do, but at the same time, it gets us the predicted rating for the users to the restaurants without visiting them or rated them unlike baselines. 

In the sections that follow, we will go over several existing studies that lay the foundation for our work and then follow it up with a brief data discovery and our proposed methodology. Consequently we present our results in relation to our experiments and then conclude with relevant takeaways from the current study.


\section{The existing technologies and studies}

Several studies have been performed over the past few decades to build search engines in different walks of life [1-3]. Wissner et al. patented a search system that generates user-customized search results with the use of user-defined semantic types even as late as 2015 [3]. There have been successful attempts to create a search engine for hotel recommendations for Expedia users by training open-source data from Kaggle with SVM and decision tree to direct a given textual query to “hotel cluster” corresponding to it [4]. Among the most recent studies that tie hotel recommendations for special purposes like vacation or business into flight information was done by Thomas et al. [5] where they devised a system as a cascaded machine learning pipeline, which would be equipped to identify an optimal list of relevant hotels based on all information about the trip. There have also been numerous studies that have used Yelp data-sets in order to design recommender systems for predicting user preferences [6], or ratings in general [7]. Jayashree and Kulkarni (2017)[8]  have also tried to make a model for restaurant recommendation with Item-based collaborative filtering using sentiment analysis as a feedback but their model needs user's reviews for prediction of the ratings. In the sections that follow, we explore the analysis part of our work and then present valuable insights we get from the said analysis.

\section{Data Discovery and Proposed Methodology}
In this section, we discuss the rationale behind choosing a particular data-set, the process of gathering initial insights on the data and detailed description of the proposed methodology.
\subsection{Rationale behind choosing particular data-set} 
We found good amount of organized Yelp data in Kaggle in JSON format [9]. It had detailed Yelp reviews for businesses including but not limited to restaurants from all users from 2005 to 2018 in different cities across the country. Out of all businesses, restaurants had the biggest fraction of reviews. Therefore, from a JSON file of 6 gigabytes size, only businesses tagged as "restaurant" were extracted out. Our aim in this study was to possibly explore different avenues in NLP without excessive computation load. At the same time, having a really small data could make for a very limited and non-generalized study. So, we decided to choose a city with 10k-20k data-points. Avondale, AZ turned out to be one of them. The final extracted CSV file with the relevant information is 7 megabytes in size. 
\subsection{Data Discovery} 
In our finalised dataset, there are seven relevant attributes  : Review ID, User ID, Business ID, Restaurant Name, Stars, Text Reviews, Date. After filtering out data for restaurants in Avondale, AZ with reviews and ratings, as shown in the Table 1, there are 12662 reviews by 8031 unique users for 163 unique restaurants. Text Review is used for sentiment analysis; rating is the ground truth label for measuring the accuracy of the model as well as used to find the cosine similarities among restaurants; business id and user id served as the key for data wrangling.
\begin{table}[H]
\centering
\caption{Information on Our Dataset- Restaurants' Reviews of Avondale, AZ}
\begin{tabular}{p{1cm}|p{2.5cm}|p{1cm}|p{1cm}}
    \hline
     Number of Reviews  & Features Included & Number of Unique users & Number of Unique Restaurants \\
    \hline
    12662 & reviewID, userID, businessID, restaurant name, stars, Text Reviews, Date & 8031 & 163 \\

\hline
\end{tabular}
\end{table}
In this section, Some of the interesting features of our data-set are presented. Figure 1 shows distinct feature - 20 most reviewed restaurants and their counts. \textit{Flavors of Louisiana} is the most reviewed restaurant in Avondale with more than 700 reviews. In another feature, Figure 2(a) shows its ratings over the years.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.3\textwidth]{mostreviewed.png}
    \caption{Twenty Most Reviewed Restaurants in Avondale}
    \label{fig:my_label1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.25\textwidth]{fol.png}
    \includegraphics[width=0.35\textwidth]{toprated.png}
    \caption{(a) Ratings of "Flavors of Louisiana" over the years (top), (b)  Twenty Top Rated Restaurants in Avondale (bottom)}
    \label{fig:my_label2}
\end{figure}

\begin{table}[H]
\centering
\caption{Star Distribution of Restaurants Ratings}
\begin{tabular}{p{2.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}}
    \hline
     Stars  & 1.0 & 2.0 & 3.0 & 4.0 & 5.0 \\
    \hline
    Distribution in Percentage & 16.2 & 9.8 & 11.0 & 21.6 & 41.4\\

\hline
\end{tabular}
\end{table}
Figure 2 (b) represents twenty top rated restaurants and their average 
ratings. \textit{Colados Coffee and Crepes} is the top-rated restaurant with around 4.7 average stars. It is interesting to know that the star 
ratings (out of 5) for the restaurant reviews are not uniformly distributed. As shown in Table 2, about $60$ percentage of these reviews rate the corresponding restaurants very highly (at least 4 stars); the other classes are smaller. 

Moreover, distribution of rating frequency of all the restaurants as well as the distribution of frequency of ratings given by the users follow the long tail property. In case of restaurants, there are very few restaurants that are rated frequently - called popular restaurants. In figure 3(a), it can be seen that only 40 restaurants are rated more than 100 times. Similarly, Rating Frequency per user is also plotted in Figure 3(b). It can be seen that very less users are interested in rating restaurants.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.2\textwidth]{restratingdistribution.png}
    \includegraphics[width=0.2\textwidth]{usersratingdistri.png}
    \caption{ Rating Distributions (a) Rating Frequency against Restaurants (left), (b) Rating Frequency per User (right)}
    \label{fig:my_label5}
\end{figure}
\subsection{Big Picture} 
As discussed before, the big picture of this study involves performing sentiment analysis on all the reviews on one hand and building an item-based collaborative filtering model to recommend restaurants based on favourite restaurant on the other. Eventually, the two aspects are to be merged together into one platform where a given user with a given "favourite restaurant" will get a list of restaurants along with predicted ratings based on the built model. Hence, the entire procedure can be broadly classified into three subsections. 
\subsection{Methodology: Baseline Discovery and High-Level Work Flow Description} 
If we could simply use reviews to predict ratings of a restaurants, that would be relatively simple. A study by Yu et al. (2017) used "bag of words" approach for the reviews and then did sentiment analysis using SVM [8]. However, the scenario here is relatively more complicated. Since we will  be recommending a user some restaurant which he/she has not paid to visit to or has written a review about beforehand, there would not be a review to implement a rating-prediction tool on. Hence, we will try to create user and restaurant "profiles" based off of all the reviews made by an user or all the reviews placed under a restaurant respectively. Then we intend to form a vector representing both the user and the restaurant profile to represent the event of a given user visiting a given restaurant. 

An attempt of combining sentiment analysis with item-based collaborative filtering was done by Jayashree and Kulkarni (2017)[8]. They combined (1) sentiment analysis by SVM with (2) item based collaborative filtering using kNN and Naive Bayes'. For our current study we use this method to create one baseline. Since the paper did not mention anything about the way the reviews were converted into training matrix, we take the liberty of experimenting with different techniques learnt in class (in the subsection that follows) and choose the best performing technique as baseline. Going by a finding in the study performed by Yu et al. (2017), that advises use of linear-based classifier like SVM or Logistic Regression for sentiment analysis to yield maximum accuracy [10], our study limits itself to exploring SVM with "linear" kernel and Logistic Regression for the sentiment analysis segment and discussing findings with respect to different aspects of performance.

\subsubsection{Baseline Discovery} Before creating a baseline, we have to look at different word embedding techniques to represent the reviews. For that purpose, it is essential to explore different ways and discard methods that provide less encouraging accuracy results at this stage. We initially start with using "bag of centroids" approach on word embedding that we learn to use in Assignment 2 of this course. Instead of using word2vec, however we use \textit{FastText}, an open-source library provided by Facebook AI lab [11] because it is believed to retain slightly better syntactical information and perform better for a small data-set like ours [12]. Firstly, we use all the words available in the review list without removing the stopwords to be trained using \textit{FastText}. That creates an array of vectors with each vector representing words in the model vocabulary. Applying k-means clustering on the array of vectors and using elbow method (figure below), we find out that using 10 clusters would be the optimal for this data-set.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.25\textwidth]{clustering.png}
    \caption{Elbow method with point of inflection around k=10}
    \label{fig:my_label7}
\end{figure}

Using 10 clusters, each of the reviews in the data-set was represented as a bag of centroids where it provides a counter for the number of times the words in the reviews feature in a particular cluster. Once we form the training matrix X, we split that into 80-20 to make dummy train and test sets. For cross-validation, we split the train set data in 80:20 ratio to optimize the regularization parameter C using "linear" kernel for SVM. The values for C are chosen at random ranging from E-4 to E4. For this case, the model is expected to perform best for C=1.19. It must be mentioned that to maintain consistency and retain a scope for a fair comparison among different approaches, we have same
\begin{enumerate}
    \item Train-test split procedure (80:20)
    \item Fixed k-fold cross validation with k=5
    \item Use of F1 score for accuracy.
    \item Use of \textbf{Google Colab} (connected to \textit{"Python 3 Google Compute Engine Backend"} with 12.72 GB RAM and 2.2 GHz Processor) with minimal interference with other processes.
\end{enumerate}  procedures for test-train-split, cross-validation and hyper-parameter optimization throughout the rest of this study. The test accuracy of the resultant model turned out to be 41.1 percent. While it is better than a random classifier which would have a 20 percent probability of classifying reviews (ratings 1-5) correctly, it is essential that we explore other baselines that would yield better performance. We try using logistic regression with tuning the "Inverse of regularization strength" parameter C in it. This process yielded a test accuracy of 41.4 percent. With respect to accuracy, that was not a significant jump, however it is worth mentioning that the run-time was observed with hyper-parameter tuning process, 30 iterations of Linear SVM (300.46 seconds) took almost 4 times of what same number of Logistic Regression (82.06 seconds) iterations took to compute. 


In quest for better performance, it is essential to explore other ways to represent texts. In a blog posted by nadbor (2016), the arithmetic mean of word2vec vector representations of the words in a piece of text is used to represent the said piece of text [13]. In our data-set, we can take the mean of the words in the reviews to create vector representations of the reviews. When we train the resulting matrix for ratings using Linear SVM, the optimum C value was found to be 3.22 and the corresponding F1 score turned out to be 53.2 percent. The test score here was 55.3 percent. That was a significant jump over the accuracy returns from "bag of centroids" approach. This could be because of the fact that bag of centroids generalizes words to one of ten centroids. This causes generalization in review representation and depletes the inherent domain knowledge. In addition, we train the matrix using Logistic Regression and get F1 score of 56.1 percent and test accuracy of 58.3 percent at significantly reduced run-time.

\subsubsection{High-Level Work Flow Description}
As the Mean-Vector representation showed better performance for rating prediction, we will proceed forward with that technique for creating matrix for rating prediction training. Since a user will be recommended restaurants where he/she has not visited beforehand, we will not have prior information about any review for the user-restaurant pair. So, the plan is to use all the reviews made by a user and create mean-vector representation of that to represent an interpretation of "user profile". In a similar manner, we take all the reviews placed against a restaurant, create mean-vector representation of that and call that the "restaurant profile". Then instead of using the provided reviews, if user $U$ with "user profile" vector $V_{U}$ makes a Review represented with vector $r$ in a restaurant $R$ which has a "restaurant profile" vector of $V_{R}$, instead of using the review $r$, we use the appended vector $[V_{U} V_{R}]$. We call it the association vector ($Assoc(U, R)$) between a user and a restaurant. This provides us with a luxury of associating any user with any restaurant that the user may not have any visit to before.

$Assoc(U, R)=[V_{U} V_{R}]$

$Review(U_{i}, R_{j}: Rating_{i, j}$ ---> $Assoc(U_{i}, R_{j}): Rating{i, j}$
As we train this $Assoc$ matrix to predict ratings, the model becomes capable of predicting rating for a given user in a given restaurant. In parallel, item-based collaborative filtering is done using kNN based solely on the ratings following the methodology explained in the GitHub repository of $KevinLiao$ [14]. As we follow the method explained, we find the cosine similarities among restaurants using the ratings given by the users to the restaurants. Additionally, we use fuzzy string matching to find the closest restaurant in our dataset with the "favourite restaurant" given in the query. By finding the 20 nearest neighbors of the closest matching restaurant, we get the top 20 recommendations with each one having distance metric with the given input. Since this part only involves the ratings and does not include information about the reviews, experimenting and fine-tuning this part of the project is out of the scope of this class. We merely use this to create a list of top X restaurants that are to be recommended for a user with given "favourite restaurant" based on the ratings they provide on different restaurants. Once we have the list of restaurants, we can leverage the user and restaurant profiles extracted from the first section of the model to predict the star ratings for the restaurants. We then multiply the distance metric from collaborative filtering (that shows relevance) and predicted rating (that depict restaurant fondness) to create a hybrid rating for the restaurants. We finally sort the restaurants based on the hybrid ratings. The high level architecture looks like \href{https://colab.research.google.com/drive/1IcFERYYH63-JIoa93ywXwm_KWJli7p1l}{\textbf{this}}.



\section{Results}
In this section, we present the rating prediction performance of the Assoc Matrix against the baselines discussed in previous section. For clarification, we reiterate the established baselines:
\begin{enumerate}
    \item Rating Prediction Model trained using Linear SVM following Jayashree and Kulkarni (2017).
    \item Rating Prediction Model trained using Logistic Regression
\end{enumerate}
We can intuitively imply that both these baselines are expected to do better than the $Assoc$ Matrix approach that we devised because the rating prediction coming directly from individual review is expected to have more specific information for a particular user-restaurant pair and combining all reviews of a user to all reviews of a restaurant could be expected to affect the pair specific domain knowledge of the specific user-restaurant pair. So, our aim was to observe if Assoc Matrix trained model can give results that are close enough to the baseline accuracy to justify the trade-off. Performance of the model is not solely defined by the accuracy. In addition, the computation time, should be one of the key reasons to choose one model over the other in form of a tie-breaker.

\subsection{Rating Prediction: Accuracy}
We created the $Assoc$ Matrix for the data and treated them to SVM with varying regularization parameter C as before. After hyper-parameter tuning and cross validation, the C for optimum performance was 41.98 and the F1 score and the test score when treated with that turned out to 51.2 percent and 50.4 percent respectively. We replicated the procedure with Logistic Regression. Logistic Regression with C=590.17 gave a F1 score of 51.05 percent and a test score of 52.5 percent. When compared to the baselines, the accuracy with Logistic regression fares around the same ballpark. Hence we look into the run-time in the next section. Figure 5(a) shows the performance bar-graph, when compared to our baselines.

\subsection{Rating Prediction: Computation Time}
Comparing the run-time for SVM and Logistic Regression with our baselines, there is an obvious increase in run-time which can be attributed to doubling of dimension of our approach [figure 5(b)]. With our Logistic regression model being significantly faster than our SVM baseline, it is our clear choice.
 \begin{figure}[H]
    \centering
    \includegraphics[width=0.32\textwidth]{accuracy-compare.png}
    \includegraphics[width=0.32\textwidth]{runtime-compare.png}
    \caption{Rating Prediction Comparison with Baselines: (a) Test Accuracy (top), (b) Run-time (bottom)}
    \label{fig:my_label_1}
\end{figure}

\subsection{Item-based Collaborative Filtering: kNN}
As mentioned above, in this section, we recommend using traditional Item-based collaborative Filtering. Following figure shows 10 recommended restaurants in the results along with the distances when favourite restaurant - $McDonald's$ is given as an input. Cosine distances of all the recommended restaurants look quite promising. In this filtering, text reviews are not used and only star ratings are used to feed kNN model with k value as 20. Resulting distances will be further used for hybrid rating. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{item_based.png}
    \caption{Recommendation Results using item-based collaborative filtering}
    \label{fig:my_label13}
\end{figure}

\subsection{Hybrid Rating Prediction and Restaurant Recommendation}
On one hand, given a "favourite restaurant", we get the top 20 restaurants for that person based on collaborative filtering model built in previous section. rating prediction model. On the other hand, we use the user-review-profile of the specific user and restaurant-review-profile for the  restaurants featuring in the list to form $Assoc$ vectors. Using the Logistic Regression based rating prediction model, we predict the star rating for each user-restaurant pair. We multiply the distance metric and the predicted rating metric together to create our hybrid metric. Then we sort the restaurants in the decreasing order of their hybrid rating. The following figure depicts an example of top 20 relevant restaurants for user with id $'uFVAAe0JC81IPmxgT49Hcw'$ with "Chipotle" as his/her favourite restaurant displayed in the decreasing order of the hybrid \begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{hybridrating.png}
    \caption{Hybrid Restaurant Recommendation for a user who likes Chipotle}
    \label{fig:my_label14}
\end{figure}
\subsection{Python GUI Interface}
Our model has already been built with reasonable accuracy, so we created a GUI interface using Python's \textit{Tkinter} library to make it more interactive.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{pythongui.png}
    \caption{Python GUI Interface using TKinter}
    \label{fig:my_label14}
\end{figure}
\section{Conclusion}
This study gave us an opportunity to do try different NLP techniques to leverage reviews to build a rating prediction tool. While we explored different avenues for analysis, there are different aspects that will be explored or could been explored with more time. 
\subsection{Findings from the Analysis}
Primarily the most important takeaways from this project were:
\begin{enumerate}
    \item \textbf{\textit{The "better" classifier:}} Computation time for Logistic Regression for our data was significantly lower than Linear SVM and we both similar performance with both the models for this data. So Logistic Regression model was preferred.
    \item \textbf{\textit{Novelty in our approach: How good were we?}} Our rating prediction tool consistently predicted 50-60 percent correctly. While that may not be perfect, it must be considered that there are 5 stars and the random classification could predict with 20 percent accuracy. While we did just slightly worse than the baseline accuracy, our approach uses individual "review profile" which means unlike baseline approaches, we do not need the user go to a given restaurant to predict his/ her star ratings. Hence that trade-off in accuracy enables us to merge the two worlds of sentiment analysis and item-based collaborative filtering.
    \item \textbf{\textit{Analysis better suited for denser user-restaurant data-set}}: While the item-based collaborative filtering recommendation model was built with success, having data-set with less sparse matrix would have made for a better model. What we mean by this is, the model would recommend more definitively if we have data with frequent occurrences of a single user reviewing multiple restaurants. Hence having a less tail heavy data for restaurants would be more ideal for our experiments.
\end{enumerate}
\subsection{Limitations and Future Analysis Prospect}
There are several directions we could have attacked the problem in, in order to better our model. We will make attempts to explore a few of these in the remaining time.
\begin{enumerate}
    \item \textbf{\textit{Other Doc2vec Techniques:}} To create our training matrix, we explored "bag of centroids" apporach as shown in HW2 of this course and eventually took the average of the word vectors in a text piece to represent the given text to create our training matrix. We could explore other operations, such as simple summation of word-vectors.
    \item \textbf{\textit{Different Analysis Techniques:}} Firstly, Other word embedding techniques such as GloVe and BERT could have been explored. Also, Linear SVM has a tendency not to converge within 100 iterations which is the default number of $"max\_iter"$ hyper-parameter. To keep most things unchanged, we did not play with this parameter. However, having higher maximum iteration would better convergence of the model. That however could not performed without compounding into the already high computation time for SVM when compared to Logistic regression model.
    \item \textbf{\textit{Introducing NLP into collaborative filtering:}}Instead of using just the ratings for item-based collaborative filtering, the reviews could have been used as a part of it making this section of the analysis more inclusive and comprehensive.
    \item \textbf{\textit{Considering Time Factor:}} People's opinion can change with time. We have considered all ratings and reviews together and analyzed without considering time as a factor. That avenue could be explored in future.
\end{enumerate}
While the work is not free of limitations and drawbacks, the study displayed an interesting way of combining analysis derived from text and pure numbers. If some of the aforementioned points are explored, there is a possibility for encountering more of such fascinating results.
\subsection{Contribution}
%All team members have contributed a similar amount of effort.
Vitaly V. Marin barely contributed in any aspect of the project while the rest of us worked on different aspects of the project both individually and collectively. This is roughly the workload distribution for our team:
\begin{table}[H]
\centering
\caption{Project Workload Distribution}
\begin{tabular}{p{2cm}|p{2cm}|p{2cm}}
    \hline
     Somdut  & Devanshee & Vitaly  \\
    \hline
    49\% & 49\% & 2\%\\
\hline
\end{tabular}
\end{table}
\section{Resources}
\small{
\begin{enumerate}[label={[\arabic*]}]
    \item A. Kruger et al. 2000. Deadliner. Proceedings of the ninth international conference on Information and knowledge management - CIKM 00 (2000). DOI:http://dx.doi.org/10.1145/354756.354829
    \item A. Gulli and A. Signorini. 2005. Building an open source meta-search engine. Special interest tracks and posters of the 14th international conference on World Wide Web - WWW 05 (2005). DOI:http://dx.doi.org/10.1145/1062745.1062840
    \item J. M. Wissner, and N. T. Spivack. 2015. Generating user-customized search results and building a semantics-enhanced search engine. U.S. Patent No. 9,037,567. 19 May 2015.
    \item Susan Li. 2018. A Machine Learning Approach - Building a Hotel Recommendation Engine. (December 2018). Retrieved April 26, 2020 from https://towardsdatascience.com/a-machine-learning-approach-building-a-hotel-recommendation-engine-6812bfd53f50
    \item E. Thomas et al. 2019. Cascaded Machine Learning Model for Efficient Hotel Recommendations from Air Travel Bookings. RecTour 2019 9.
    \item Vladimir Nikulin. 2014. Hybrid Recommender System for Prediction of the Yelp Users Preferences. Advances in Data Mining. Applications and Theoretical Aspects Lecture Notes in Computer Science (2014), 85–99. DOI:http://dx.doi.org/10.1007/978-3-319-08976-8\_7
    \item Farhan, Wael. 2014. Predicting Yelp Restaurant Reviews. UC San Diego, La Jolla (2014).
    \item R. Jayashree and Deepa Kulkarni. 2017. Recommendation System with Sentiment Analysis as Feedback Component. Advances in Intelligent Systems and Computing Proceedings of Sixth International Conference on Soft Computing for Problem Solving (2017), 359–367.
    DOI:http://dx.doi.org/10.1007/978-981-10-3325-4\_36
    \item Yelp, Inc. 2020. Yelp Dataset. (March 2020). Retrieved March 28, 2020 from https://www.kaggle.com/yelp-dataset/yelp-dataset
    \item Boya Yu, Jiaxu Zhou, Yi Zhang, and Yunong Cao. 2017. Identifying Restaurant Features via Sentiment Analysis on Yelp Reviews. Identifying Restaurant Features via Sentiment Analysis on Yelp Reviews (2017).
    \item Facebookresearch. 2020. facebookresearch/fastText. (March 2020). Retrieved March 28, 2020 from https://github.com/facebookresearch/fastText
    \item Anon. 2016. FastText and Gensim word embeddings. (August 2016). Retrieved March 28, 2020 from https://rare-technologies.com/fasttext-and-gensim-word-embeddings/
    \item Nadbor. 2016. DS lore. (May 2016). Retrieved March 28, 2020 from http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/
    \item KevinLiao159. KevinLiao159/MyDataSciencePortfolio. Retrieved March 28, 2020 from https://tinyurl.com/cse6240-item-based-reference
    
\end{enumerate}}
\newpage
\section{Appendix}

\end{document}
\endinput
